{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as snsa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pydot\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from Final_dm_tool import data_prep \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the importances of all features to decide which feature to remove.\n",
    "def analyse_feature_importance(dm_model, feature_names, n_to_display=20):\n",
    "    # grab feature importances from the model\n",
    "    importances = dm_model.feature_importances_\n",
    "    \n",
    "    # sort them out in descending order\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    # limit to 20 features, you can leave this out to print out everything\n",
    "    indices = indices[:n_to_display]\n",
    "\n",
    "    print(\"\\n\\n*********** Feature Importances ************\\n\")   \n",
    "    for i in indices:\n",
    "        print(f\"{feature_names[i]:<35}:{importances[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_decision_tree(dm_model, feature_names, save_name):\n",
    "    dotfile = StringIO()\n",
    "    export_graphviz(dm_model, out_file=dotfile, feature_names=feature_names, filled=True, rounded=True)\n",
    "    graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "    graph[0].write_png(save_name) # saved in the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of_tree(model):\n",
    "\n",
    "\n",
    "# Using those arrays, we can parse the tree structure:\n",
    "\n",
    "    n_nodes = model.tree_.node_count\n",
    "    children_left = model.tree_.children_left\n",
    "    children_right = model.tree_.children_right\n",
    "    feature = model.tree_.feature\n",
    "    threshold = model.tree_.threshold\n",
    "\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    \n",
    "    \n",
    "    # Calculate decision node\n",
    "    decision_node_number = 0\n",
    "    leaf_node_number = 0\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            leaf_node_number = leaf_node_number + 1\n",
    "        else:\n",
    "            decision_node_number = decision_node_number + 1\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\n\\n*********** Size of decision tree ************\\n\") \n",
    "    print(\"The binary tree structure has %s nodes and has \" \"the following tree structure:\" % n_nodes)\n",
    "    print(\"The tree has %s decision nodes.\" % decision_node_number)\n",
    "    print(\"The tree has %s leaf nodes.\" % leaf_node_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# preprocessing step\n",
    "df = data_prep()\n",
    "\n",
    "# target/input split\n",
    "y = df['IsBadBuy']\n",
    "X = df.drop(['IsBadBuy'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7511, 125)\n",
      "(3219, 125)\n",
      "(7511,)\n",
      "(3219,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# setting random state\n",
    "# .as_matrix removed replaced with .values\n",
    "# train test 70 / 30 percent\n",
    "rs = 10\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** Evaluation of the decision tree ************\n",
      "\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.7496116806461635\n",
      "\n",
      "\n",
      "*********** Confusion Matrix ************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      1609\n",
      "           1       0.75      0.74      0.75      1610\n",
      "\n",
      "    accuracy                           0.75      3219\n",
      "   macro avg       0.75      0.75      0.75      3219\n",
      "weighted avg       0.75      0.75      0.75      3219\n",
      "\n",
      "\n",
      "\n",
      "*********** Feature Importances ************\n",
      "\n",
      "Auction_ADESA                      :0.19951016019947423\n",
      "MMRCurrentAuctionAveragePrice      :0.08850121619510157\n",
      "VehOdo                             :0.05467146361906708\n",
      "VehBCost                           :0.0538048384103142\n",
      "MMRCurrentRetailRatio              :0.04000160585099367\n",
      "VNST_OK                            :0.036412515793597014\n",
      "WarrantyCost                       :0.032699127207786054\n",
      "MMRCurrentRetailCleanPrice         :0.03249131031610065\n",
      "MMRAcquisitionAuctionAveragePrice  :0.02796893939991498\n",
      "MMRAcquisitionAuctionCleanPrice    :0.02766899672875254\n",
      "MMRAcquisitionRetailAveragePrice   :0.027664009051721023\n",
      "MMRAcquisitonRetailCleanPrice      :0.02742412015087629\n",
      "VNST_CO                            :0.02603726183750516\n",
      "Auction_OTHER                      :0.019547871083264445\n",
      "MMRCurrentAuctionCleanPrice        :0.016177330077786628\n",
      "VNST_AZ                            :0.0161641404607167\n",
      "VNST_PA                            :0.014729430579449318\n",
      "Auction_MANHEIM                    :0.01471069884735225\n",
      "VNST_CA                            :0.014539973652830477\n",
      "MMRCurrentRetailAveragePrice       :0.012284708068352272\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 1967 nodes and has the following tree structure:\n",
      "The tree has 983 decision nodes.\n",
      "The tree has 984 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "# simple decision tree training with default setting\n",
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# decision tree evaluation\n",
    "print(\"\\n\\n*********** Evaluation of the decision tree ************\\n\") \n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\\n*********** Confusion Matrix ************\\n\") \n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "analyse_feature_importance(model, X.columns, 20)\n",
    "\n",
    "#visualising the model\n",
    "visualize_decision_tree(model, X.columns, \"default.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "print(\"\\n\\n*********** Size of decision tree ************\\n\") \n",
    "size_of_tree(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Decision Tree model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** Evaluation of the decision tree ************\n",
      "\n",
      "Train accuracy: 0.75902010384769\n",
      "Test accuracy: 0.7567567567567568\n",
      "\n",
      "\n",
      "*********** Confusion Matrix ************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77      1609\n",
      "           1       0.80      0.68      0.74      1610\n",
      "\n",
      "    accuracy                           0.76      3219\n",
      "   macro avg       0.76      0.76      0.76      3219\n",
      "weighted avg       0.76      0.76      0.76      3219\n",
      "\n",
      "\n",
      "\n",
      "*********** Feature Importances ************\n",
      "\n",
      "Auction_ADESA                      :0.571435214578175\n",
      "MMRCurrentAuctionAveragePrice      :0.1454371788211704\n",
      "VNST_OK                            :0.09192443745447534\n",
      "VNST_CO                            :0.051861359005029174\n",
      "VNST_AZ                            :0.03242171935598875\n",
      "VNST_PA                            :0.029128640102322405\n",
      "Auction_OTHER                      :0.02742613108261397\n",
      "VehBCost                           :0.025783852802885004\n",
      "VNST_CA                            :0.015410298161252467\n",
      "VNST_TX                            :0.004722860655972494\n",
      "MMRCurrentRetailRatio              :0.004448307980114939\n",
      "Make_LINCOLN                       :0.0\n",
      "Make_LEXUS                         :0.0\n",
      "Make_JEEP                          :0.0\n",
      "Make_KIA                           :0.0\n",
      "Make_MERCURY                       :0.0\n",
      "Make_ISUZU                         :0.0\n",
      "Make_INFINITI                      :0.0\n",
      "Make_HYUNDAI                       :0.0\n",
      "Make_HONDA                         :0.0\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 23 nodes and has the following tree structure:\n",
      "The tree has 11 decision nodes.\n",
      "The tree has 12 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "#retrain with a small max_depth limit 5\n",
    "model_2 = DecisionTreeClassifier(max_depth=5, random_state=rs, )\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "# decision tree evaluation\n",
    "print(\"\\n\\n*********** Evaluation of the decision tree ************\\n\") \n",
    "print(\"Train accuracy:\", model_2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model_2.score(X_test, y_test))\n",
    "\n",
    "#confusoin matrix\n",
    "print(\"\\n\\n*********** Confusion Matrix ************\\n\") \n",
    "y_pred = model_2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "analyse_feature_importance(model_2, X.columns, 20)\n",
    "\n",
    "#visualising the model\n",
    "visualize_decision_tree(model_2, X.columns, \"second_tree.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "size_of_tree(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the performance of model with different complexity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_score = []\n",
    "train_score = []\n",
    "\n",
    "# check the model performance for max depth from 2-20\n",
    "for max_depth in range(2, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=rs)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_score.append(model.score(X_test, y_test))\n",
    "    train_score.append(model.score(X_train, y_train))\n",
    "    \n",
    "# plot max depth hyperparameter values vs training and test accuracy score\n",
    "plt.plot(range(2, 21), train_score, 'b', range(2,21), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7648781786712822\n",
      "Test accuracy: 0.7555141348244796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1609\n",
      "           1       0.80      0.68      0.73      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.76      0.76      0.75      3219\n",
      "weighted avg       0.76      0.76      0.75      3219\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(3, 9),\n",
    "          'min_samples_leaf': range(20, 80, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7648781786712822\n",
      "Test accuracy: 0.7555141348244796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1609\n",
      "           1       0.80      0.68      0.73      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.76      0.76      0.75      3219\n",
      "weighted avg       0.76      0.76      0.75      3219\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 26}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV #2\n",
    "params = {'criterion': ['gini'],\n",
    "          'max_depth': range(4, 9),\n",
    "          'min_samples_leaf': range(20, 35)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** Evaluation of the decision tree ************\n",
      "\n",
      "Train accuracy: 0.7638130741579018\n",
      "Test accuracy: 0.7601739670705188\n",
      "\n",
      "\n",
      "*********** Confusion Matrix ************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78      1609\n",
      "           1       0.81      0.68      0.74      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.77      0.76      0.76      3219\n",
      "weighted avg       0.77      0.76      0.76      3219\n",
      "\n",
      "\n",
      "\n",
      "*********** Feature Importances ************\n",
      "\n",
      "Auction_ADESA                      :0.5422671171500951\n",
      "MMRCurrentAuctionAveragePrice      :0.13801354497205165\n",
      "VNST_OK                            :0.08723228534468135\n",
      "VNST_CO                            :0.04921416972858956\n",
      "VNST_AZ                            :0.030766798824604577\n",
      "VNST_PA                            :0.027641810115690942\n",
      "Auction_MANHEIM                    :0.026026203246378853\n",
      "VNST_MO                            :0.025090514534735073\n",
      "VehBCost                           :0.02446775272462682\n",
      "VNST_CA                            :0.014623701419056629\n",
      "VNST_NC                            :0.01254757997967377\n",
      "VNST_FL                            :0.006523228827706428\n",
      "MMRCurrentRetailRatio              :0.0062168351504326745\n",
      "VNST_TX                            :0.004481788953987272\n",
      "MMRAcquisitionAuctionAveragePrice  :0.003104321403774169\n",
      "MMRCurrentRetailAveragePrice       :0.0017823476239150367\n",
      "Make_INFINITI                      :0.0\n",
      "Make_MAZDA                         :0.0\n",
      "Make_HONDA                         :0.0\n",
      "Make_MERCURY                       :0.0\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 35 nodes and has the following tree structure:\n",
      "The tree has 17 decision nodes.\n",
      "The tree has 18 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "# Assigining the best parameter to optimal model\n",
    "Optimal_model = DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 6,  min_samples_leaf = 26)\n",
    "\n",
    "Optimal_model.fit(X_train, y_train)\n",
    "\n",
    "# decision tree evaluation\n",
    "print(\"\\n\\n*********** Evaluation of the decision tree ************\\n\") \n",
    "print(\"Train accuracy:\", Optimal_model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", Optimal_model.score(X_test, y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\\n*********** Confusion Matrix ************\\n\") \n",
    "y_pred = Optimal_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "analyse_feature_importance(Optimal_model, X.columns, 20)\n",
    "\n",
    "#visualising the model\n",
    "visualize_decision_tree(Optimal_model, X.columns, \"Optimal_model.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "size_of_tree(Optimal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of decison tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 35 nodes and has the following tree structure:\n",
      "node=0 test node: go to node 1 if X[:, 13] <= 0.5 else to node 34.\n",
      "\tnode=1 test node: go to node 2 if X[:, 6] <= 4738.0 else to node 25.\n",
      "\t\tnode=2 test node: go to node 3 if X[:, 97] <= 0.5 else to node 16.\n",
      "\t\t\tnode=3 test node: go to node 4 if X[:, 11] <= 4240.0 else to node 11.\n",
      "\t\t\t\tnode=4 test node: go to node 5 if X[:, 120] <= 0.5 else to node 8.\n",
      "\t\t\t\t\tnode=5 test node: go to node 6 if X[:, 98] <= 0.5 else to node 7.\n",
      "\t\t\t\t\t\tnode=6 leaf node.\n",
      "\t\t\t\t\t\tnode=7 leaf node.\n",
      "\t\t\t\t\tnode=8 test node: go to node 9 if X[:, 2] <= 3358.0 else to node 10.\n",
      "\t\t\t\t\t\tnode=9 leaf node.\n",
      "\t\t\t\t\t\tnode=10 leaf node.\n",
      "\t\t\t\tnode=11 test node: go to node 12 if X[:, 96] <= 0.5 else to node 15.\n",
      "\t\t\t\t\tnode=12 test node: go to node 13 if X[:, 107] <= 0.5 else to node 14.\n",
      "\t\t\t\t\t\tnode=13 leaf node.\n",
      "\t\t\t\t\t\tnode=14 leaf node.\n",
      "\t\t\t\t\tnode=15 leaf node.\n",
      "\t\t\tnode=16 test node: go to node 17 if X[:, 14] <= 0.5 else to node 18.\n",
      "\t\t\t\tnode=17 leaf node.\n",
      "\t\t\t\tnode=18 test node: go to node 19 if X[:, 10] <= 0.8278218507766724 else to node 22.\n",
      "\t\t\t\t\tnode=19 test node: go to node 20 if X[:, 8] <= 5535.5 else to node 21.\n",
      "\t\t\t\t\t\tnode=20 leaf node.\n",
      "\t\t\t\t\t\tnode=21 leaf node.\n",
      "\t\t\t\t\tnode=22 test node: go to node 23 if X[:, 10] <= 0.8855109214782715 else to node 24.\n",
      "\t\t\t\t\t\tnode=23 leaf node.\n",
      "\t\t\t\t\t\tnode=24 leaf node.\n",
      "\t\tnode=25 test node: go to node 26 if X[:, 115] <= 0.5 else to node 33.\n",
      "\t\t\tnode=26 test node: go to node 27 if X[:, 95] <= 0.5 else to node 32.\n",
      "\t\t\t\tnode=27 test node: go to node 28 if X[:, 117] <= 0.5 else to node 31.\n",
      "\t\t\t\t\tnode=28 test node: go to node 29 if X[:, 105] <= 0.5 else to node 30.\n",
      "\t\t\t\t\t\tnode=29 leaf node.\n",
      "\t\t\t\t\t\tnode=30 leaf node.\n",
      "\t\t\t\t\tnode=31 leaf node.\n",
      "\t\t\t\tnode=32 leaf node.\n",
      "\t\t\tnode=33 leaf node.\n",
      "\tnode=34 leaf node.\n",
      "\n",
      "Rules used to predict sample 0: \n",
      "decision id node 0 : (X_test[0, 13] (= 0.0) <= 0.5)\n",
      "decision id node 1 : (X_test[0, 6] (= 8260.0) > 4738.0)\n",
      "decision id node 25 : (X_test[0, 115] (= 0.0) <= 0.5)\n",
      "decision id node 26 : (X_test[0, 95] (= 0.0) <= 0.5)\n",
      "decision id node 27 : (X_test[0, 117] (= 0.0) <= 0.5)\n",
      "decision id node 28 : (X_test[0, 105] (= 0.0) <= 0.5)\n",
      "\n",
      "The following samples [0, 1] share the node [ 0  1 25 26 27 28 29] in the tree\n",
      "It is 20.0 % of all nodes.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 35 nodes and has the following tree structure:\n",
      "The tree has 17 decision nodes.\n",
      "The tree has 18 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "# The decision estimator has an attribute called tree_  which stores the entire\n",
    "# tree structure and allows access to low level attributes. The binary tree\n",
    "# tree_ is represented as a number of parallel arrays. The i-th element of each\n",
    "# array holds information about the node `i`. Node 0 is the tree's root. NOTE:\n",
    "# Some of the arrays only apply to either leaves or split nodes, resp. In this\n",
    "# case the values of nodes of the other type are arbitrary!\n",
    "#\n",
    "# Among those arrays, we have:\n",
    "#   - left_child, id of the left child of the node\n",
    "#   - right_child, id of the right child of the node\n",
    "#   - feature, feature used for splitting the node\n",
    "#   - threshold, threshold value at the node\n",
    "#\n",
    "\n",
    "# Using those arrays, we can parse the tree structure:\n",
    "\n",
    "n_nodes = Optimal_model.tree_.node_count\n",
    "children_left = Optimal_model.tree_.children_left\n",
    "children_right = Optimal_model.tree_.children_right\n",
    "feature = Optimal_model.tree_.feature\n",
    "threshold = Optimal_model.tree_.threshold\n",
    "\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "\n",
    "# Calculate decision node\n",
    "decision_node_number = 0\n",
    "leaf_node_number = 0\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        leaf_node_number = leaf_node_number + 1\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        decision_node_number = decision_node_number + 1\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()\n",
    "\n",
    "    \n",
    "# First let's retrieve the decision path of each sample. The decision_path\n",
    "# method allows to retrieve the node indicator functions. A non zero element of\n",
    "# indicator matrix at the position (i, j) indicates that the sample i goes\n",
    "# through the node j.\n",
    "\n",
    "node_indicator = Optimal_model.decision_path(X_test)\n",
    "\n",
    "# Similarly, we can also have the leaves ids reached by each sample.\n",
    "\n",
    "leave_id = Optimal_model.apply(X_test)\n",
    "\n",
    "# Now, it's possible to get the tests that were used to predict a sample or\n",
    "# a group of samples. First, let's make it for the sample.\n",
    "\n",
    "sample_id = 0\n",
    "node_index = node_indicator.indices[node_indicator.indptr[sample_id]:\n",
    "                                    node_indicator.indptr[sample_id + 1]]\n",
    "\n",
    "print('Rules used to predict sample %s: ' % sample_id)\n",
    "for node_id in node_index:\n",
    "    if leave_id[sample_id] == node_id:\n",
    "        continue\n",
    "\n",
    "    if (X_test[sample_id, feature[node_id]] <= threshold[node_id]):\n",
    "        threshold_sign = \"<=\"\n",
    "    else:\n",
    "        threshold_sign = \">\"\n",
    "\n",
    "    print(\"decision id node %s : (X_test[%s, %s] (= %s) %s %s)\"\n",
    "          % (node_id,\n",
    "             sample_id,\n",
    "             feature[node_id],\n",
    "             X_test[sample_id, feature[node_id]],\n",
    "             threshold_sign,\n",
    "             threshold[node_id]))\n",
    "\n",
    "# For a group of samples, we have the following common node.\n",
    "sample_ids = [0, 1]\n",
    "common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==\n",
    "                len(sample_ids))\n",
    "\n",
    "common_node_id = np.arange(n_nodes)[common_nodes]\n",
    "\n",
    "print(\"\\nThe following samples %s share the node %s in the tree\"\n",
    "      % (sample_ids, common_node_id))\n",
    "print(\"It is %s %% of all nodes.\" % (100 * len(common_node_id) / n_nodes,))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"\\n\\n*********** Size of decision tree ************\\n\") \n",
    "print(\"The binary tree structure has %s nodes and has \" \"the following tree structure:\" % n_nodes)\n",
    "print(\"The tree has %s decision nodes.\" % decision_node_number)\n",
    "print(\"The tree has %s leaf nodes.\" % leaf_node_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
